{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258320ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeMo Curator version: 1.1.0rc0.dev0\n",
      "✓ Core modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Test basic imports\n",
    "import nemo_curator\n",
    "print(f\"NeMo Curator version: {nemo_curator.__version__}\")\n",
    "\n",
    "from nemo_curator.pipeline import Pipeline\n",
    "from nemo_curator.tasks import DocumentBatch\n",
    "print(\"✓ Core modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c4ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GPU available: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "✓ GPU memory: 8.6 GB\n",
      "⚠ Some GPU modules not available: No module named 'cudf'\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✓ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"✓ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    else:\n",
    "        print(\"⚠ No GPU detected\")\n",
    "    \n",
    "    # Check cuDF for GPU deduplication\n",
    "    import cudf\n",
    "    print(\"✓ cuDF available for GPU-accelerated deduplication\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Some GPU modules not available: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd65181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'nemo_curator' from '/home/agam/projects/Data_Curation/Curator/nemo_curator/__init__.py'>\n",
      "/home/agam/projects/Data_Curation/Curator/nemo_curator/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import nemo_curator\n",
    "print(nemo_curator)\n",
    "print(nemo_curator.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a5acbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json, os\n",
    "\n",
    "ds = load_dataset(\"roneneldan/TinyStories\", split=\"train[:1%]\")\n",
    "\n",
    "os.makedirs(\"books\", exist_ok=True)\n",
    "\n",
    "with open(\"books/data.jsonl\", \"w\") as f:\n",
    "    for ex in ds:\n",
    "        f.write(json.dumps({\"text\": ex[\"text\"]}) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e057f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-15 16:00:29.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnemo_curator.core.client\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m106\u001b[0m - \u001b[33m\u001b[1mNo monitoring services are running. Please run the `start_prometheus_grafana.py` script from nemo_curator/metrics folder to setup monitoring services separately.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.core.client\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mRay is already running. Skipping the setup.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_reader' to pipeline 'basic_curation'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'UnicodeReformatter' to pipeline 'basic_curation'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'NewlineNormalizer' to pipeline 'basic_curation'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'UrlRemover' to pipeline 'basic_curation'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'remove_question_sentences' to pipeline 'basic_curation'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'word_count' to pipeline 'basic_curation'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'basic_curation'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: basic_curation\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: jsonl_reader\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'jsonl_reader' into 2 execution stages\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
      "2026-02-15 16:00:29,161\tINFO worker.py:1696 -- Using address 127.0.1.1:6379 set in the environment variable RAY_ADDRESS\n",
      "2026-02-15 16:00:29,163\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 127.0.1.1:6379...\n",
      "2026-02-15 16:00:29,175\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[32m2026-02-15 16:00:29.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
      "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
      "  job_info: None\n",
      "  Stage 0:\n",
      "   class_name: FilePartitioningStage\n",
      "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: 1\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 1:\n",
      "   class_name: JsonlReaderStage\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 2:\n",
      "   class_name: Modify\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 3:\n",
      "   class_name: Modify\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 4:\n",
      "   class_name: Modify\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 5:\n",
      "   class_name: Modify\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 6:\n",
      "   class_name: Filter\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 7:\n",
      "   class_name: JsonlWriter\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:29.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
      "2026-02-15 16:00:29,206\tINFO worker.py:1696 -- Using address 127.0.1.1:6379 set in the environment variable RAY_ADDRESS\n",
      "2026-02-15 16:00:29,208\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 127.0.1.1:6379...\n",
      "2026-02-15 16:00:29,208\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[32m2026-02-15 16:00:29.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.114\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_get_local_gpu_info\u001b[0m:\u001b[36m731\u001b[0m - \u001b[33m\u001b[1mpynvml is not installed. Assuming no GPUs.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m762\u001b[0m - \u001b[1mNo gpus found. Returning None.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=19.0, gpus=0.0, nvdecs=0.0, nvencs=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373': NodeResources(cpus=19, gpus=[], name='fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 04 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 05 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 06 - Filter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 07 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
      "{ 'cluster_resources': { 'cpus': 19.0,\n",
      "                         'gpus': 0.0,\n",
      "                         'nvdecs': 0.0,\n",
      "                         'nvencs': 0.0},\n",
      "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 00 - FilePartitioningStage',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': 1,\n",
      "                'resources_per_worker': { 'cpus': 0.5,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 01 - JsonlReaderStage',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 02 - Modify',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 03 - Modify',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 04 - Modify',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 05 - Modify',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 06 - Filter',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 07 - JsonlWriter',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1}]}\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
      "{ 'allocation_result': { 'cluster_resources': { 'cpus': 19.0,\n",
      "                                                'gpus': 0.0,\n",
      "                                                'nvdecs': 0.0,\n",
      "                                                'nvencs': 0.0},\n",
      "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 1,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 00 - '\n",
      "                                                            'FilePartitioningStage',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': 1,\n",
      "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 2,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 01 - '\n",
      "                                                            'JsonlReaderStage',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 2,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 02 - Modify',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 2,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 03 - Modify',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 2,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 04 - Modify',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 2,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 05 - Modify',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 2,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 06 - Filter',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 2,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 07 - '\n",
      "                                                            'JsonlWriter',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}}],\n",
      "                         'throughput': 1.0},\n",
      "  'num_slots_per_state': [2, 2, 2, 2, 2, 2, 2, 2]}\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:31.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 4.194893836975098 seconds to get node resource info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.01613306999206543 seconds to get cluster info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.018871545791625977 seconds to get actor info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 4.239227533340454 to get stats.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
      "Pipeline duration: 0.07176391283671062 minutes\n",
      "Number of initial input samples: 1\n",
      "Number of input samples remaining: 1\n",
      "Streaming pipeline main loop rate: 0\n",
      "\n",
      "Cluster Resources:\n",
      "╒══════════════════════════╤══════════╤═════════════╕\n",
      "│ Resource                 │    Total │   Available │\n",
      "╞══════════════════════════╪══════════╪═════════════╡\n",
      "│ CPUs                     │ 20       │    19       │\n",
      "├──────────────────────────┼──────────┼─────────────┤\n",
      "│ GPUs                     │  1       │     1       │\n",
      "├──────────────────────────┼──────────┼─────────────┤\n",
      "│ Memory (GB)              │  5.54874 │     5.54874 │\n",
      "├──────────────────────────┼──────────┼─────────────┤\n",
      "│ Object Store Memory (GB) │  2.37803 │     2.37803 │\n",
      "╘══════════════════════════╧══════════╧═════════════╛\n",
      "\n",
      "Resource Usage by Stage:\n",
      "╒══════════════════════════════════╤═════════╤═══════════════╤═══════════════╤════════════════════╤══════════════════════════╕\n",
      "│ Stage                            │   CPU % │   Memory (GB) │   Actor Count │   CPU % per worker │   Memory (GB) per worker │\n",
      "╞══════════════════════════════════╪═════════╪═══════════════╪═══════════════╪════════════════════╪══════════════════════════╡\n",
      "│ Stage 00 - FilePartitioningStage │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 01 - JsonlReaderStage      │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 02 - Modify                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 03 - Modify                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 04 - Modify                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 05 - Modify                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 06 - Filter                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 07 - JsonlWriter           │       0 │             0 │             0 │                  0 │                        0 │\n",
      "╘══════════════════════════════════╧═════════╧═══════════════╧═══════════════╧════════════════════╧══════════════════════════╛\n",
      "\n",
      "Stage state:\n",
      "╒══════════════════════════════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═════════════╤═════════════════╤══════════════╤═══════════════╤════════════╤═════════════╤═════════════════╕\n",
      "│ Stage                            │   Actors: │   Actors: │   Actors: │   Actors: │   Actors: │      Tasks: │          Tasks: │       Queue: │        Queue: │     Slots: │      Slots: │ Speed:          │\n",
      "│                                  │    Target │   Pending │     Ready │   Running │      Idle │   Completed │   Returned None │   Input Size │   Output Size │   Num Used │   Num Empty │ Tasks/actor/s   │\n",
      "╞══════════════════════════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═════════════╪═════════════════╪══════════════╪═══════════════╪════════════╪═════════════╪═════════════════╡\n",
      "│ Stage 00 - FilePartitioningStage │         0 │         1 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 01 - JsonlReaderStage      │         0 │         3 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 02 - Modify                │         0 │         3 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 03 - Modify                │         0 │         3 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 04 - Modify                │         0 │         3 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 05 - Modify                │         0 │         2 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 06 - Filter                │         0 │         2 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 07 - JsonlWriter           │         0 │         2 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "╘══════════════════════════════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═════════════╧═════════════════╧══════════════╧═══════════════╧════════════╧═════════════╧═════════════════╛\u001b[0m\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.900 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.900 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.903 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.904 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.929 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:173 - Getting file list for books/\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.933 | INFO     | nemo_curator.stages.file_partitioning:process:100 - Found 1 files\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.933 | INFO     | nemo_curator.stages.file_partitioning:process:111 - No partitions specified, defaulting to one file per partition\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=61985)\u001b[0m 2026-02-15 16:00:35.933 | INFO     | nemo_curator.stages.file_partitioning:process:137 - Created 1 file groups from 1 files\n",
      "\u001b[32m2026-02-15 16:00:35.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=61987)\u001b[0m 2026-02-15 16:00:35.919 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=61987)\u001b[0m 2026-02-15 16:00:35.919 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=61987)\u001b[0m 2026-02-15 16:00:35.923 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=61987)\u001b[0m 2026-02-15 16:00:35.923 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
      "\u001b[32m2026-02-15 16:00:35.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:35.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 3 actor IDs across all states to terminate.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 15.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 15 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 8.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 8 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:36.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:40.382\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_move_pending_node_actor_to_pending\u001b[0m:\u001b[36m764\u001b[0m - \u001b[31m\u001b[1mUnexpected error getting node setup result for node fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373, actor 6: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 127.0.1.1, ID: fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373) where the lease (actor ID: NIL_IDlease ID: 4c00000068ab5ab087a6d1733075b6d9b01adb858fb93c8826f4d52a5a99beef, name=StageWorker.__init__, pid=61986, memory used=0.35GB) was running was 10.96GB / 11.54GB (0.950381), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 3c765097396831e75561e7a03ad9928a4e6d851a23ca9a405d2a3a30) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 127.0.1.1`. To see the logs of the worker, use `ray logs worker-3c765097396831e75561e7a03ad9928a4e6d851a23ca9a405d2a3a30*out -ip 127.0.1.1. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "54739\t0.48\tray::StageWorker\n",
      "54735\t0.46\tray::StageWorker\n",
      "54741\t0.45\tray::StageWorker\n",
      "54740\t0.45\tray::StageWorker\n",
      "54731\t0.45\tray::StageWorker\n",
      "54746\t0.45\tray::StageWorker\n",
      "54733\t0.45\tray::StageWorker\n",
      "25632\t0.37\t/home/agam/.vscode-server/bin/b6a47e94e326b5c209d118cf0f994d6065585705/node --dns-result-order=ipv4f...\n",
      "61982\t0.35\tray::StageWorker.__init__\n",
      "61997\t0.35\tray::StageWorker.__init__\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:40.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.0040874481201171875 seconds to get node resource info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:40.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.012632369995117188 seconds to get cluster info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:40.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.00844883918762207 seconds to get actor info.\u001b[0m\n",
      "\u001b[36m(Stage 02 - Modify pid=61984)\u001b[0m 2026-02-15 16:00:43.431 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 02 - Modify pid=61984)\u001b[0m 2026-02-15 16:00:43.431 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=61996)\u001b[0m 2026-02-15 16:00:35.968 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=61996)\u001b[0m 2026-02-15 16:00:35.969 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[32m2026-02-15 16:00:50.415\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m150\u001b[0m - \u001b[31m\u001b[1mPipeline execution failed: Unexpected error during node setup for stage Stage 06 - Filter.\u001b[0m\n",
      "\u001b[36m(Stage 05 - Modify pid=61991)\u001b[0m 2026-02-15 16:00:43.431 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 05 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(Stage 05 - Modify pid=61991)\u001b[0m 2026-02-15 16:00:43.431 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 05 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error during node setup for stage Stage 06 - Filter.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:727\u001b[39m, in \u001b[36mActorPool._move_pending_node_actor_to_pending\u001b[39m\u001b[34m(self, node_id)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    726\u001b[39m     \u001b[38;5;66;03m# Block until node setup completes or fails\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m     \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_setup_actor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode_setup_call_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _VERBOSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py:104\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/worker.py:2972\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(object_refs, timeout, _tensor_transport)\u001b[39m\n\u001b[32m   2967\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2968\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, is given. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2969\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mobject_refs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2970\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2972\u001b[39m values, debugger_breakpoint = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_tensor_transport\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_tensor_transport\u001b[49m\n\u001b[32m   2974\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2975\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/worker.py:1033\u001b[39m, in \u001b[36mWorker.get_objects\u001b[39m\u001b[34m(self, object_refs, timeout, return_exceptions, skip_deserialization, _tensor_transport)\u001b[39m\n\u001b[32m   1032\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values, debugger_breakpoint\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 127.0.1.1, ID: fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373) where the lease (actor ID: NIL_IDlease ID: 4c00000068ab5ab087a6d1733075b6d9b01adb858fb93c8826f4d52a5a99beef, name=StageWorker.__init__, pid=61986, memory used=0.35GB) was running was 10.96GB / 11.54GB (0.950381), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 3c765097396831e75561e7a03ad9928a4e6d851a23ca9a405d2a3a30) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 127.0.1.1`. To see the logs of the worker, use `ray logs worker-3c765097396831e75561e7a03ad9928a4e6d851a23ca9a405d2a3a30*out -ip 127.0.1.1. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n54739\t0.48\tray::StageWorker\n54735\t0.46\tray::StageWorker\n54741\t0.45\tray::StageWorker\n54740\t0.45\tray::StageWorker\n54731\t0.45\tray::StageWorker\n54746\t0.45\tray::StageWorker\n54733\t0.45\tray::StageWorker\n25632\t0.37\t/home/agam/.vscode-server/bin/b6a47e94e326b5c209d118cf0f994d6065585705/node --dns-result-order=ipv4f...\n61982\t0.35\tray::StageWorker.__init__\n61997\t0.35\tray::StageWorker.__init__\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     58\u001b[39m     ray_client.stop()\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Writer\u001b[39;00m\n\u001b[32m     55\u001b[39m pipeline.add_stage(JsonlWriter(path=\u001b[33m\"\u001b[39m\u001b[33mcurated_books/\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m ray_client.stop()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/nemo_curator/pipeline/pipeline.py:197\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, executor, initial_tasks)\u001b[39m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnemo_curator\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxenna\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XennaExecutor\n\u001b[32m    195\u001b[39m     executor = XennaExecutor()\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_tasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/nemo_curator/backends/xenna/executor.py:147\u001b[39m, in \u001b[36mXennaExecutor.execute\u001b[39m\u001b[34m(self, stages, initial_tasks)\u001b[39m\n\u001b[32m    139\u001b[39m     ray.init(\n\u001b[32m    140\u001b[39m         ignore_reinit_error=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    141\u001b[39m         runtime_env={\n\u001b[32m   (...)\u001b[39m\u001b[32m    144\u001b[39m         },\n\u001b[32m    145\u001b[39m     )\n\u001b[32m    146\u001b[39m     \u001b[38;5;66;03m# Run the pipeline (this will re-initialize ray but that'll be a no-op and the ray.init above will take precedence)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     results = \u001b[43mpipelines_v1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPipeline completed successfully with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mresults\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m output tasks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/pipelines/private/pipelines.py:168\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(pipeline_spec)\u001b[39m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pipeline_spec.config.mode_specific \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    167\u001b[39m         pipeline_spec.config.mode_specific = specs.StreamingSpecificSpec()\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstreaming\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_resources\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pipeline_spec.config.execution_mode == specs.ExecutionMode.BATCH:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m batch.run_pipeline(pipeline_spec, cluster_resources)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/pipelines/private/streaming.py:440\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(pipeline_spec, cluster_resources)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pool, is_done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pools, stage_is_dones):\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_done:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m         \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m new_stats.pool_update_end = time.time()\n\u001b[32m    443\u001b[39m \u001b[38;5;66;03m# Grab stats from the pools\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:1135\u001b[39m, in \u001b[36mActorPool.update\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1133\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_resize_num_slots_per_actor()\n\u001b[32m   1134\u001b[39m \u001b[38;5;66;03m# 2. Check for completed node setups and advance waiting/setup actors\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_pending_node_setup_actors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# 3. Check for completed individual setups and move actors to ready\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28mself\u001b[39m._move_pending_actors_to_ready()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:790\u001b[39m, in \u001b[36mActorPool._check_pending_node_setup_actors\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m node_id = ref_to_node_id_map.get(ready_ref)\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;129;01mand\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pending_node_actors:  \u001b[38;5;66;03m# Check if still pending node setup\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_move_pending_node_actor_to_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:770\u001b[39m, in \u001b[36mActorPool._move_pending_node_actor_to_pending\u001b[39m\u001b[34m(self, node_id)\u001b[39m\n\u001b[32m    768\u001b[39m \u001b[38;5;28mself\u001b[39m._allocator.delete_worker(node_setup_actor.metadata.worker.id)\n\u001b[32m    769\u001b[39m \u001b[38;5;66;03m# Handle unexpected errors similarly - potentially promote another waiter or fail\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected error during node setup for stage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unexpected error during node setup for stage Stage 06 - Filter."
     ]
    }
   ],
   "source": [
    "from nemo_curator.core.client import RayClient\n",
    "from nemo_curator.pipeline import Pipeline\n",
    "\n",
    "# IO\n",
    "from nemo_curator.stages.text.io.reader import JsonlReader\n",
    "from nemo_curator.stages.text.io.writer import JsonlWriter\n",
    "\n",
    "from nemo_curator.stages.text.modifiers import (\n",
    "    UnicodeReformatter,\n",
    "    UrlRemover,\n",
    "    NewlineNormalizer\n",
    ")\n",
    "\n",
    "from nemo_curator.stages.text.modules import Modify, Filter\n",
    "\n",
    "from nemo_curator.stages.text.filters import WordCountFilter\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def remove_question_sentences(text: str) -> str:\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    sentences = [s for s in sentences if not s.strip().endswith(\"?\")]\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "\n",
    "def main():\n",
    "    ray_client = RayClient()\n",
    "    ray_client.start()\n",
    "\n",
    "    pipeline = Pipeline(name=\"basic_curation\")\n",
    "\n",
    "    pipeline.add_stage(JsonlReader(file_paths=\"books/\"))\n",
    "\n",
    "    pipeline.add_stage(Modify(UnicodeReformatter()))\n",
    "    pipeline.add_stage(Modify(NewlineNormalizer()))\n",
    "    pipeline.add_stage(Modify(UrlRemover()))\n",
    "    pipeline.add_stage(Modify(remove_question_sentences))\n",
    "\n",
    "    pipeline.add_stage(\n",
    "        Filter(\n",
    "            WordCountFilter(min_words=20),\n",
    "            filter_field=\"text\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    pipeline.add_stage(JsonlWriter(path=\"curated_books/\"))\n",
    "\n",
    "    pipeline.run()\n",
    "    ray_client.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50283800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-15 16:17:06.544\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnemo_curator.core.client\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m106\u001b[0m - \u001b[33m\u001b[1mNo monitoring services are running. Please run the `start_prometheus_grafana.py` script from nemo_curator/metrics folder to setup monitoring services separately.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.core.client\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mRay is already running. Skipping the setup.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_reader' to pipeline 'text_cleaning_pipeline'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'UnicodeReformatter' to pipeline 'text_cleaning_pipeline'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'NewlineNormalizer' to pipeline 'text_cleaning_pipeline'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'UrlRemover' to pipeline 'text_cleaning_pipeline'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36madd_stage\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mAdded stage 'jsonl_writer' to pipeline 'text_cleaning_pipeline'\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mPlanning pipeline: text_cleaning_pipeline\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mDecomposing composite stage: jsonl_reader\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.pipeline.pipeline\u001b[0m:\u001b[36m_decompose_stages\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mExpanded 'jsonl_reader' into 2 execution stages\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mExecution mode: STREAMING\u001b[0m\n",
      "2026-02-15 16:17:06,552\tINFO worker.py:1696 -- Using address 127.0.1.1:6379 set in the environment variable RAY_ADDRESS\n",
      "2026-02-15 16:17:06,555\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 127.0.1.1:6379...\n",
      "2026-02-15 16:17:06,564\tINFO worker.py:2014 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[32m2026-02-15 16:17:06.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mPipelineSpec:\n",
      "  config: PipelineConfig(execution_mode=<ExecutionMode.STREAMING: 0>, num_setup_attempts_python=1, num_run_attempts_python=1, max_setup_failure_percentage=None, ignore_failures=False, reset_workers_on_failure=False, slots_per_actor=2, worker_max_lifetime_m=0, worker_restart_interval_m=1, logging_interval_s=60, failures_return_nones=False, return_last_stage_outputs=True, actor_pool_verbosity_level=<VerbosityLevel.INFO: 1>, monitoring_verbosity_level=<VerbosityLevel.INFO: 1>, mode_specific=StreamingSpecificSpec(autoscale_interval_s=180, autoscaler_verbosity_level=<VerbosityLevel.INFO: 1>, executor_verbosity_level=<VerbosityLevel.INFO: 1>), log_worker_allocation_layout=True, cpu_allocation_percentage=0.95, clear_cuda_visible_devices_on_cpu_actors=True)\n",
      "  job_info: None\n",
      "  Stage 0:\n",
      "   class_name: FilePartitioningStage\n",
      "   required_resources: Resources(cpus=0.5, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: 1\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 1:\n",
      "   class_name: JsonlReaderStage\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 2:\n",
      "   class_name: Modify\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 3:\n",
      "   class_name: Modify\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 4:\n",
      "   class_name: Modify\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "  Stage 5:\n",
      "   class_name: JsonlWriter\n",
      "   required_resources: Resources(cpus=1.0, gpus=0.0, nvdecs=0, nvencs=0, entire_gpu=False)\n",
      "   shape: WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0))\n",
      "      num_workers: None\n",
      "      num_workers_per_node: None\n",
      "      num_setup_attempts_python: 1\n",
      "      num_run_attempts_python: 1\n",
      "      ignore_failures: False\n",
      "      reset_workers_on_failure: False\n",
      "      slots_per_actor: 2\n",
      "      worker_max_lifetime_m: 0\n",
      "      worker_restart_interval_m: 1\n",
      "      max_setup_failure_percentage: None\n",
      "      over_provision_factor: None\n",
      "\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:06.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mInitialized Ray cluster.\u001b[0m\n",
      "2026-02-15 16:17:06,594\tINFO worker.py:1696 -- Using address 127.0.1.1:6379 set in the environment variable RAY_ADDRESS\n",
      "2026-02-15 16:17:06,597\tINFO worker.py:1837 -- Connecting to existing Ray cluster at address: 127.0.1.1:6379...\n",
      "2026-02-15 16:17:06,598\tINFO worker.py:1855 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[32m2026-02-15 16:17:06.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.cluster\u001b[0m:\u001b[36minit_or_connect_to_cluster\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mRay dashboard url: 127.0.0.1:8265\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m759\u001b[0m - \u001b[1mDetermining number of nvdecs/nvencs per gpu in this cluster.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.767\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_get_local_gpu_info\u001b[0m:\u001b[36m731\u001b[0m - \u001b[33m\u001b[1mpynvml is not installed. Assuming no GPUs.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.resources\u001b[0m:\u001b[36m_make_gpu_resources_from_current_node\u001b[0m:\u001b[36m762\u001b[0m - \u001b[1mNo gpus found. Returning None.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.pipelines\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mCreated/connected to cluster with resources: PoolOfResources(cpus=19.0, gpus=0.0, nvdecs=0.0, nvencs=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=0.5, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnemo_curator.backends.xenna.adapter\u001b[0m:\u001b[36mrequired_resources\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mResources: Resources(cpus=1.0, gpu_memory_gb=0.0, nvdecs=0, nvencs=0, entire_gpu=False, gpus=0.0)\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m854\u001b[0m - \u001b[1mSetting up fragmentation based autoscaler with problem: Problem(cluster_resources=ClusterResources(nodes={'fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373': NodeResources(cpus=19, gpus=[], name='fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373')}), stages=[ProblemStage(name='Stage 00 - FilePartitioningStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=0.5)), requested_num_workers=1, over_provision_factor=None), ProblemStage(name='Stage 01 - JsonlReaderStage', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 02 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 03 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 04 - Modify', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None), ProblemStage(name='Stage 05 - JsonlWriter', stage_batch_size=1, worker_shape=WorkerShape(type=<WorkerShapeType.CPU_ONLY: 0>, data=CpuOnly(num_cpus=1.0)), requested_num_workers=None, over_provision_factor=None)])\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mStarting main loop\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mAutoscaling...\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mSolving the following naiive allocation problem:\n",
      "{ 'cluster_resources': { 'cpus': 19.0,\n",
      "                         'gpus': 0.0,\n",
      "                         'nvdecs': 0.0,\n",
      "                         'nvencs': 0.0},\n",
      "  'stages': [ { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 00 - FilePartitioningStage',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': 1,\n",
      "                'resources_per_worker': { 'cpus': 0.5,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 01 - JsonlReaderStage',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 02 - Modify',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 03 - Modify',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 04 - Modify',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1},\n",
      "              { 'batches_per_second_per_worker': 1.0,\n",
      "                'name': 'Stage 05 - JsonlWriter',\n",
      "                'num_returns_per_batch': 1,\n",
      "                'requested_num_workers': None,\n",
      "                'resources_per_worker': { 'cpus': 1.0,\n",
      "                                          'gpus': 0,\n",
      "                                          'nvdecs': 0,\n",
      "                                          'nvencs': 0},\n",
      "                'stage_batch_size': 1}]}\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36m_run_naiive_allocation\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mGot the following naiive allocation result:\n",
      "{ 'allocation_result': { 'cluster_resources': { 'cpus': 19.0,\n",
      "                                                'gpus': 0.0,\n",
      "                                                'nvdecs': 0.0,\n",
      "                                                'nvencs': 0.0},\n",
      "                         'stages': [ { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 1,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 00 - '\n",
      "                                                            'FilePartitioningStage',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': 1,\n",
      "                                                    'resources_per_worker': { 'cpus': 0.5,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 3,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 01 - '\n",
      "                                                            'JsonlReaderStage',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 3,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 02 - Modify',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 3,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 03 - Modify',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 3,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 04 - Modify',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}},\n",
      "                                     { 'input_samples_per_sample': 1.0,\n",
      "                                       'num_workers': 3,\n",
      "                                       'problem': { 'batches_per_second_per_worker': 1.0,\n",
      "                                                    'name': 'Stage 05 - '\n",
      "                                                            'JsonlWriter',\n",
      "                                                    'num_returns_per_batch': 1,\n",
      "                                                    'requested_num_workers': None,\n",
      "                                                    'resources_per_worker': { 'cpus': 1.0,\n",
      "                                                                              'gpus': 0,\n",
      "                                                                              'nvdecs': 0,\n",
      "                                                                              'nvencs': 0},\n",
      "                                                    'stage_batch_size': 1}}],\n",
      "                         'throughput': 1.0},\n",
      "  'num_slots_per_state': [2, 2, 2, 2, 2, 2]}\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.scheduling.autoscaling_algorithms\u001b[0m:\u001b[36mrun_fragmentation_autoscaler\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mRunning phase 4...\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:08.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mDone calculating autoscaling...\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 5.205187082290649 seconds to get node resource info.\u001b[0m\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.091 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 00 - FilePartitioningStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.091 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=77545)\u001b[0m 2026-02-15 16:17:14.094 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 01 - JsonlReaderStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=77545)\u001b[0m 2026-02-15 16:17:14.095 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[32m2026-02-15 16:17:14.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.02158808708190918 seconds to get cluster info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.014180660247802734 seconds to get actor info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36mupdate\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mtook 5.244756460189819 to get stats.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_print_state\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mPipeline Stats:\n",
      "Pipeline duration: 0.08884218533833822 minutes\n",
      "Number of initial input samples: 1\n",
      "Number of input samples remaining: 1\n",
      "Streaming pipeline main loop rate: 0\n",
      "\n",
      "Cluster Resources:\n",
      "╒══════════════════════════╤══════════╤═════════════╕\n",
      "│ Resource                 │    Total │   Available │\n",
      "╞══════════════════════════╪══════════╪═════════════╡\n",
      "│ CPUs                     │ 20       │    19       │\n",
      "├──────────────────────────┼──────────┼─────────────┤\n",
      "│ GPUs                     │  1       │     1       │\n",
      "├──────────────────────────┼──────────┼─────────────┤\n",
      "│ Memory (GB)              │  5.54874 │     5.54874 │\n",
      "├──────────────────────────┼──────────┼─────────────┤\n",
      "│ Object Store Memory (GB) │  2.37803 │     2.37803 │\n",
      "╘══════════════════════════╧══════════╧═════════════╛\n",
      "\n",
      "Resource Usage by Stage:\n",
      "╒══════════════════════════════════╤═════════╤═══════════════╤═══════════════╤════════════════════╤══════════════════════════╕\n",
      "│ Stage                            │   CPU % │   Memory (GB) │   Actor Count │   CPU % per worker │   Memory (GB) per worker │\n",
      "╞══════════════════════════════════╪═════════╪═══════════════╪═══════════════╪════════════════════╪══════════════════════════╡\n",
      "│ Stage 00 - FilePartitioningStage │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 01 - JsonlReaderStage      │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 02 - Modify                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 03 - Modify                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 04 - Modify                │       0 │             0 │             0 │                  0 │                        0 │\n",
      "├──────────────────────────────────┼─────────┼───────────────┼───────────────┼────────────────────┼──────────────────────────┤\n",
      "│ Stage 05 - JsonlWriter           │       0 │             0 │             0 │                  0 │                        0 │\n",
      "╘══════════════════════════════════╧═════════╧═══════════════╧═══════════════╧════════════════════╧══════════════════════════╛\n",
      "\n",
      "Stage state:\n",
      "╒══════════════════════════════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═════════════╤═════════════════╤══════════════╤═══════════════╤════════════╤═════════════╤═════════════════╕\n",
      "│ Stage                            │   Actors: │   Actors: │   Actors: │   Actors: │   Actors: │      Tasks: │          Tasks: │       Queue: │        Queue: │     Slots: │      Slots: │ Speed:          │\n",
      "│                                  │    Target │   Pending │     Ready │   Running │      Idle │   Completed │   Returned None │   Input Size │   Output Size │   Num Used │   Num Empty │ Tasks/actor/s   │\n",
      "╞══════════════════════════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═════════════╪═════════════════╪══════════════╪═══════════════╪════════════╪═════════════╪═════════════════╡\n",
      "│ Stage 00 - FilePartitioningStage │         0 │         1 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 01 - JsonlReaderStage      │         0 │         4 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 02 - Modify                │         0 │         4 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 03 - Modify                │         0 │         4 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 04 - Modify                │         0 │         3 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "├──────────────────────────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼─────────────┼─────────────────┼──────────────┼───────────────┼────────────┼─────────────┼─────────────────┤\n",
      "│ Stage 05 - JsonlWriter           │         0 │         3 │         0 │         0 │         0 │           0 │               0 │            0 │             0 │          0 │           0 │                 │\n",
      "╘══════════════════════════════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═════════════╧═════════════════╧══════════════╧═══════════════╧════════════╧═════════════╧═════════════════╛\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 0\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 00 - FilePartitioningStage. Terminating all actors.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 1 actor IDs across all states to terminate.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 0.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 0 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 00 - FilePartitioningStage stopped. All states cleared.\u001b[0m\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=77545)\u001b[0m 2026-02-15 16:17:14.132 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=77545)\u001b[0m 2026-02-15 16:17:14.132 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.131 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 00 - FilePartitioningStage\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.131 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 00 - FilePartitioningStage\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.155 | DEBUG    | nemo_curator.stages.file_partitioning:_get_file_list:173 - Getting file list for books/\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.162 | INFO     | nemo_curator.stages.file_partitioning:process:100 - Found 1 files\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.162 | INFO     | nemo_curator.stages.file_partitioning:process:111 - No partitions specified, defaulting to one file per partition\n",
      "\u001b[36m(Stage 00 - FilePartitioningStage pid=77542)\u001b[0m 2026-02-15 16:17:14.162 | INFO     | nemo_curator.stages.file_partitioning:process:137 - Created 1 file groups from 1 files\n",
      "\u001b[32m2026-02-15 16:17:14.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.streaming\u001b[0m:\u001b[36mrun_pipeline\u001b[0m:\u001b[36m536\u001b[0m - \u001b[1mStopping stages 1\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1151\u001b[0m - \u001b[1mStopping actor pool Stage 01 - JsonlReaderStage. Terminating all actors.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1161\u001b[0m - \u001b[1mFound 4 actor IDs across all states to terminate.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 1.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 1 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 16.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 16 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 11.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 11 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_try_delete_ready_actor\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1mKilling ready actor 6.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_delete_actor\u001b[0m:\u001b[36m912\u001b[0m - \u001b[1mDeleting worker 6 from allocator.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:14.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m1179\u001b[0m - \u001b[1mActor pool Stage 01 - JsonlReaderStage stopped. All states cleared.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:19.906\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mcosmos_xenna.ray_utils.actor_pool\u001b[0m:\u001b[36m_move_pending_node_actor_to_pending\u001b[0m:\u001b[36m764\u001b[0m - \u001b[31m\u001b[1mUnexpected error getting node setup result for node fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373, actor 5: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 127.0.1.1, ID: fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373) where the lease (actor ID: NIL_IDlease ID: 750000004ebe27f23d60fee2322502bb8e51058dd75e4ecde1750af3ec3f45dd, name=StageWorker.__init__, pid=77543, memory used=0.33GB) was running was 11.21GB / 11.54GB (0.971874), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: eba7d6e01ebe50467c3fc440ee9fb5539b1460615d9424b50b2864fb) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 127.0.1.1`. To see the logs of the worker, use `ray logs worker-eba7d6e01ebe50467c3fc440ee9fb5539b1460615d9424b50b2864fb*out -ip 127.0.1.1. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "25632\t0.79\t/home/agam/.vscode-server/bin/b6a47e94e326b5c209d118cf0f994d6065585705/node --dns-result-order=ipv4f...\n",
      "54739\t0.48\tray::StageWorker\n",
      "54735\t0.46\tray::StageWorker\n",
      "54740\t0.45\tray::StageWorker\n",
      "54741\t0.45\tray::StageWorker\n",
      "54731\t0.45\tray::StageWorker\n",
      "54746\t0.45\tray::StageWorker\n",
      "54733\t0.45\tray::StageWorker\n",
      "25988\t0.40\t/home/agam/.vscode-server/bin/b6a47e94e326b5c209d118cf0f994d6065585705/node /home/agam/.vscode-serve...\n",
      "77551\t0.34\tray::StageWorker.__init__\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:19.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mTook 0.009291648864746094 seconds to get node resource info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:19.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mTook 0.031025171279907227 seconds to get cluster info.\u001b[0m\n",
      "\u001b[32m2026-02-15 16:17:19.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcosmos_xenna.pipelines.private.monitoring\u001b[0m:\u001b[36m_make_stats\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mTook 0.00732731819152832 seconds to get actor info.\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2026-02-15 16:17:23,199 E 39325 39325] (raylet) node_manager.cc:3277: 7 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373, IP: 127.0.1.1) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 127.0.1.1`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=77550)\u001b[0m 2026-02-15 16:17:14.141 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:422 - Setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(Stage 01 - JsonlReaderStage pid=77550)\u001b[0m 2026-02-15 16:17:14.142 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup:427 - Finished setting up actor for stage=Stage 01 - JsonlReaderStage\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(Stage 02 - Modify pid=77536)\u001b[0m 2026-02-15 16:17:24.197 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 02 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 02 - Modify pid=77536)\u001b[0m 2026-02-15 16:17:24.197 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 02 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[32m2026-02-15 16:17:29.962\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mnemo_curator.backends.xenna.executor\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m150\u001b[0m - \u001b[31m\u001b[1mPipeline execution failed: Unexpected error during node setup for stage Stage 05 - JsonlWriter.\u001b[0m\n",
      "\u001b[36m(Stage 03 - Modify pid=77551)\u001b[0m 2026-02-15 16:17:24.200 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:389 - Setting up actor for stage=Stage 03 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n",
      "\u001b[36m(Stage 03 - Modify pid=77551)\u001b[0m 2026-02-15 16:17:24.200 | INFO     | cosmos_xenna.ray_utils.stage_worker:setup_on_node:392 - Finished setting up actor for stage=Stage 03 - Modify on node=fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error during node setup for stage Stage 05 - JsonlWriter.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:727\u001b[39m, in \u001b[36mActorPool._move_pending_node_actor_to_pending\u001b[39m\u001b[34m(self, node_id)\u001b[39m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    726\u001b[39m     \u001b[38;5;66;03m# Block until node setup completes or fails\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m     \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_setup_actor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode_setup_call_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _VERBOSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py:104\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/worker.py:2972\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(object_refs, timeout, _tensor_transport)\u001b[39m\n\u001b[32m   2967\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2968\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, is given. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2969\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mobject_refs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2970\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2972\u001b[39m values, debugger_breakpoint = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_tensor_transport\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_tensor_transport\u001b[49m\n\u001b[32m   2974\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2975\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/ray/_private/worker.py:1033\u001b[39m, in \u001b[36mWorker.get_objects\u001b[39m\u001b[34m(self, object_refs, timeout, return_exceptions, skip_deserialization, _tensor_transport)\u001b[39m\n\u001b[32m   1032\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values, debugger_breakpoint\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 127.0.1.1, ID: fc54e73991ae57a761a6626fc00aaf456cec53c924b877ec6e1d1373) where the lease (actor ID: NIL_IDlease ID: 750000004ebe27f23d60fee2322502bb8e51058dd75e4ecde1750af3ec3f45dd, name=StageWorker.__init__, pid=77543, memory used=0.33GB) was running was 11.21GB / 11.54GB (0.971874), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: eba7d6e01ebe50467c3fc440ee9fb5539b1460615d9424b50b2864fb) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 127.0.1.1`. To see the logs of the worker, use `ray logs worker-eba7d6e01ebe50467c3fc440ee9fb5539b1460615d9424b50b2864fb*out -ip 127.0.1.1. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n25632\t0.79\t/home/agam/.vscode-server/bin/b6a47e94e326b5c209d118cf0f994d6065585705/node --dns-result-order=ipv4f...\n54739\t0.48\tray::StageWorker\n54735\t0.46\tray::StageWorker\n54740\t0.45\tray::StageWorker\n54741\t0.45\tray::StageWorker\n54731\t0.45\tray::StageWorker\n54746\t0.45\tray::StageWorker\n54733\t0.45\tray::StageWorker\n25988\t0.40\t/home/agam/.vscode-server/bin/b6a47e94e326b5c209d118cf0f994d6065585705/node /home/agam/.vscode-serve...\n77551\t0.34\tray::StageWorker.__init__\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     ray_client.stop()\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m pipeline.add_stage(JsonlWriter(path=\u001b[33m\"\u001b[39m\u001b[33mcleaned_books/\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Execute pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m results = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Stop Ray client\u001b[39;00m\n\u001b[32m     34\u001b[39m ray_client.stop()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/nemo_curator/pipeline/pipeline.py:197\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, executor, initial_tasks)\u001b[39m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnemo_curator\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxenna\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XennaExecutor\n\u001b[32m    195\u001b[39m     executor = XennaExecutor()\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_tasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/nemo_curator/backends/xenna/executor.py:147\u001b[39m, in \u001b[36mXennaExecutor.execute\u001b[39m\u001b[34m(self, stages, initial_tasks)\u001b[39m\n\u001b[32m    139\u001b[39m     ray.init(\n\u001b[32m    140\u001b[39m         ignore_reinit_error=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    141\u001b[39m         runtime_env={\n\u001b[32m   (...)\u001b[39m\u001b[32m    144\u001b[39m         },\n\u001b[32m    145\u001b[39m     )\n\u001b[32m    146\u001b[39m     \u001b[38;5;66;03m# Run the pipeline (this will re-initialize ray but that'll be a no-op and the ray.init above will take precedence)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     results = \u001b[43mpipelines_v1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPipeline completed successfully with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mresults\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m output tasks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/pipelines/private/pipelines.py:168\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(pipeline_spec)\u001b[39m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pipeline_spec.config.mode_specific \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    167\u001b[39m         pipeline_spec.config.mode_specific = specs.StreamingSpecificSpec()\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstreaming\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_resources\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pipeline_spec.config.execution_mode == specs.ExecutionMode.BATCH:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m batch.run_pipeline(pipeline_spec, cluster_resources)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/pipelines/private/streaming.py:440\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(pipeline_spec, cluster_resources)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pool, is_done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pools, stage_is_dones):\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_done:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m         \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m new_stats.pool_update_end = time.time()\n\u001b[32m    443\u001b[39m \u001b[38;5;66;03m# Grab stats from the pools\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:1135\u001b[39m, in \u001b[36mActorPool.update\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1133\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_resize_num_slots_per_actor()\n\u001b[32m   1134\u001b[39m \u001b[38;5;66;03m# 2. Check for completed node setups and advance waiting/setup actors\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_pending_node_setup_actors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# 3. Check for completed individual setups and move actors to ready\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28mself\u001b[39m._move_pending_actors_to_ready()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:790\u001b[39m, in \u001b[36mActorPool._check_pending_node_setup_actors\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m node_id = ref_to_node_id_map.get(ready_ref)\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node_id \u001b[38;5;129;01mand\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pending_node_actors:  \u001b[38;5;66;03m# Check if still pending node setup\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_move_pending_node_actor_to_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Data_Curation/Curator/.venv/lib/python3.12/site-packages/cosmos_xenna/ray_utils/actor_pool.py:770\u001b[39m, in \u001b[36mActorPool._move_pending_node_actor_to_pending\u001b[39m\u001b[34m(self, node_id)\u001b[39m\n\u001b[32m    768\u001b[39m \u001b[38;5;28mself\u001b[39m._allocator.delete_worker(node_setup_actor.metadata.worker.id)\n\u001b[32m    769\u001b[39m \u001b[38;5;66;03m# Handle unexpected errors similarly - potentially promote another waiter or fail\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected error during node setup for stage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unexpected error during node setup for stage Stage 05 - JsonlWriter."
     ]
    }
   ],
   "source": [
    "from nemo_curator.core.client import RayClient\n",
    "from nemo_curator.pipeline import Pipeline\n",
    "from nemo_curator.stages.text.io.reader import JsonlReader\n",
    "from nemo_curator.stages.text.io.writer import JsonlWriter\n",
    "from nemo_curator.stages.text.modifiers import UnicodeReformatter, UrlRemover, NewlineNormalizer\n",
    "from nemo_curator.stages.text.modules import Modify\n",
    "\n",
    "def main():\n",
    "    ray_client = RayClient()\n",
    "    ray_client.start()\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        name=\"text_cleaning_pipeline\",\n",
    "        description=\"Clean text data using Unicode reformatter, newline normalizer, and URL remover\"\n",
    "    )\n",
    "    \n",
    "    pipeline.add_stage(JsonlReader(file_paths=\"books/\"))\n",
    "    \n",
    "    pipeline.add_stage(Modify(UnicodeReformatter()))\n",
    "    pipeline.add_stage(Modify(NewlineNormalizer()))\n",
    "    pipeline.add_stage(Modify(UrlRemover()))\n",
    "    \n",
    "    pipeline.add_stage(JsonlWriter(path=\"cleaned_books/\"))\n",
    "\n",
    "    results = pipeline.run()\n",
    "\n",
    "    ray_client.stop()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo-curator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
